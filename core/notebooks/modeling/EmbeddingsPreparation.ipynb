{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/maaxap/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/maaxap/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data.csv\t\t MenuItemFixed.txt\t  Shifts.txt\r\n",
      "'Data Description.pdf'\t OrderEntry.txt\t\t 'Задание для дататона.docx'\r\n",
      " Data.zip\t\t OrderItems.txt\r\n",
      " MenuItem.csv\t\t RestaurantCategory.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/maaxap/workspace/data/menuby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/maaxap/workspace/data/menuby'\n",
    "data_filepath = join(data_root, 'data.csv')\n",
    "\n",
    "data = pd.read_csv(data_filepath)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\n",
    "    'user_id', 'order_id', 'item_id', \n",
    "    'count', 'description'\n",
    "]\n",
    "data = data[[\n",
    "    'user_id', 'order_id', 'item_id', \n",
    "    'description', 'count'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>description</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59960</td>\n",
       "      <td>104376</td>\n",
       "      <td>16489</td>\n",
       "      <td>Classic kebab with lamb 380g  lavash  lamb  pi...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59968</td>\n",
       "      <td>104377</td>\n",
       "      <td>2320</td>\n",
       "      <td>Whopper with cheese Set whopper with cheese  v...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54779</td>\n",
       "      <td>104378</td>\n",
       "      <td>10745</td>\n",
       "      <td>Falafel 350g</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54779</td>\n",
       "      <td>104378</td>\n",
       "      <td>12098</td>\n",
       "      <td>Vegetarian shawarma 400g  cheese  mushrooms  t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30143</td>\n",
       "      <td>104379</td>\n",
       "      <td>18732</td>\n",
       "      <td>Kagatsu maki 8pcs  116g  rice  nori  cheese Ph...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30143</td>\n",
       "      <td>104379</td>\n",
       "      <td>18726</td>\n",
       "      <td>Asahi maki 8pcs  116g  rice  nori  crab sticks...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30143</td>\n",
       "      <td>104379</td>\n",
       "      <td>18729</td>\n",
       "      <td>Kappa maki 8pcs  111g  rice  nori  cucumber</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59971</td>\n",
       "      <td>104380</td>\n",
       "      <td>14172</td>\n",
       "      <td>King Burger 460g  fried bun  cheese  fresh veg...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59971</td>\n",
       "      <td>104380</td>\n",
       "      <td>14147</td>\n",
       "      <td>Bread sticks 150g  deep fried bread sticks in ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59972</td>\n",
       "      <td>104381</td>\n",
       "      <td>4061</td>\n",
       "      <td>Pizza Lisitsa pizza sauce  ham  pepperoni  cha...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  order_id  item_id  \\\n",
       "0    59960    104376    16489   \n",
       "1    59968    104377     2320   \n",
       "2    54779    104378    10745   \n",
       "3    54779    104378    12098   \n",
       "4    30143    104379    18732   \n",
       "5    30143    104379    18726   \n",
       "6    30143    104379    18729   \n",
       "7    59971    104380    14172   \n",
       "8    59971    104380    14147   \n",
       "9    59972    104381     4061   \n",
       "\n",
       "                                         description  count  \n",
       "0  Classic kebab with lamb 380g  lavash  lamb  pi...    2.0  \n",
       "1  Whopper with cheese Set whopper with cheese  v...    1.0  \n",
       "2                                       Falafel 350g    1.0  \n",
       "3  Vegetarian shawarma 400g  cheese  mushrooms  t...    1.0  \n",
       "4  Kagatsu maki 8pcs  116g  rice  nori  cheese Ph...    2.0  \n",
       "5  Asahi maki 8pcs  116g  rice  nori  crab sticks...    2.0  \n",
       "6        Kappa maki 8pcs  111g  rice  nori  cucumber    1.0  \n",
       "7  King Burger 460g  fried bun  cheese  fresh veg...    1.0  \n",
       "8  Bread sticks 150g  deep fried bread sticks in ...    1.0  \n",
       "9  Pizza Lisitsa pizza sauce  ham  pepperoni  cha...    2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('[A-Za-z]+')\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = set(tokenizer.tokenize(text)) - stop_words\n",
    "    tokens = filter(lambda x: len(x) > 3, tokens)\n",
    "    # tokens = map(lambda x: stemmer.stem(x), tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.2 s, sys: 235 ms, total: 19.4 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['description'] = data['description'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>description</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59960</td>\n",
       "      <td>104376</td>\n",
       "      <td>16489</td>\n",
       "      <td>kebab cabbage pickled lavash tomato garlic lam...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59968</td>\n",
       "      <td>104377</td>\n",
       "      <td>2320</td>\n",
       "      <td>whopper large cheese size drink potatoes villa...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54779</td>\n",
       "      <td>104378</td>\n",
       "      <td>10745</td>\n",
       "      <td>falafel</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54779</td>\n",
       "      <td>104378</td>\n",
       "      <td>12098</td>\n",
       "      <td>vegetarian shawarma pepper bulgarian french mu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30143</td>\n",
       "      <td>104379</td>\n",
       "      <td>18732</td>\n",
       "      <td>philadelphia kagatsu nori rice omelette japane...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  order_id  item_id  \\\n",
       "0    59960    104376    16489   \n",
       "1    59968    104377     2320   \n",
       "2    54779    104378    10745   \n",
       "3    54779    104378    12098   \n",
       "4    30143    104379    18732   \n",
       "\n",
       "                                         description  count  \n",
       "0  kebab cabbage pickled lavash tomato garlic lam...    2.0  \n",
       "1  whopper large cheese size drink potatoes villa...    1.0  \n",
       "2                                            falafel    1.0  \n",
       "3  vegetarian shawarma pepper bulgarian french mu...    1.0  \n",
       "4  philadelphia kagatsu nori rice omelette japane...    2.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description'] = ((data['description'] + ' ').astype(str) * 2).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.user_id = data.user_id.astype(np.int32)\n",
    "data.order_id = data.order_id.astype(np.int32)\n",
    "data.item_id = data.item_id.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['user_id', 'order_id', 'item_id']].to_csv(join(data_root, 'labels.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(data['description'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = count_vectorizer.transform(data['description'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.sparse.save_npz(join(data_root, 'embedings.npz'), X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
